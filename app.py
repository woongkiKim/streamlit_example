import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore')
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
import pickle
import time
import joblib
from modules.charts import MakeChart

## 1. í˜ì´ì§€ ì„¤ì • (set_page_configëŠ” ë§¨ ìœ„ì— ìœ„ì¹˜)
st.set_page_config(
    page_title="LSë¹…ë°ì´í„°ìŠ¤ì¿¨ 2ê¸° Streamlit ì˜ˆì œ",
    page_icon="ğŸ­",
)


#### ğŸ“Œ 1. ì œëª© ì„¤ì •í•˜ê¸° ####
st.title("1. ì œëª© ì„¤ì •í•˜ê¸°")
st.header("Header")
st.subheader("subheader")
######################
st.divider()


#### ğŸ“Œ 2. ìœ„ì ¯ ë§Œë“¤ê¸° ####
st.title("2. ìœ„ì ¯ ë§Œë“¤ê¸°")

## ë²„íŠ¼ ë§Œë“¤ê¸°
if st.button("ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”"):
    st.write("âœ… ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆìŠµë‹ˆë‹¤.")

## ì²´í¬ë°•ìŠ¤ ë§Œë“¤ê¸°
checkbox_btn = st.checkbox('ì²´í¬ë°•ìŠ¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”')
if checkbox_btn:
    st.write('ğŸ”¥ğŸ”¥ğŸ”¥ ì²´í¬ë°•ìŠ¤ ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆìŠµë‹ˆë‹¤.')

## ì²´í¬ë°•ìŠ¤ ë””í´íŠ¸ 
checkbox_btn2 = st.checkbox('ë””í´íŠ¸ ì²´í¬ë°•ìŠ¤', value=True)
	
if checkbox_btn2:
    st.write('ì €ëŠ” ì´ë¯¸ í´ë¦­ì´ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ğŸ™ƒ')

## ë¼ë””ì˜¤ ë²„íŠ¼ ë§Œë“¤ê¸°
selected_item = st.radio("ë¼ë””ì˜¤ ë²„íŠ¼", ("A", "B", "C"))
	
if selected_item == "A":
    st.write("âœ… Aë¥¼ í´ë¦­í–ˆì–´ìš”!")
elif selected_item == "B":
    st.write("âœ…âœ… Bë¥¼ í´ë¦­í–ˆì–´ìš”!")
elif selected_item == "C":
    st.write("âœ…âœ…âœ… Cë¥¼ í´ë¦­í–ˆì–´ìš”!")

## ì˜µì…˜ ì„ íƒ
option = st.selectbox('ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”.',
                       ('1ë²ˆ ì˜µì…˜', '2ë²ˆ ì˜µì…˜', '3ë²ˆ ì˜µì…˜'))
	
st.write('âœ… ë‹¹ì‹ ì˜ ì„ íƒ :', option)

## ë‹¤ì¤‘ ì˜µì…˜ ì„ íƒ
options = st.multiselect('ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”.',
                            ('1ë²ˆ ì˜µì…˜', '2ë²ˆ ì˜µì…˜', '3ë²ˆ ì˜µì…˜'))

st.write('ğŸ”¥ğŸ”¥ë‹¹ì‹ ì˜ ì„ íƒ :', options)

## ìŠ¬ë¼ì´ë” ë§Œë“¤ê¸°
number = st.slider('ìˆ«ìë¥¼ ì„ íƒí•˜ì„¸ìš”.', min_value=0, max_value=100, value=50)
st.write('âœ… ë‹¹ì‹ ì´ ì„ íƒí•œ ìˆ«ìëŠ”', number, 'ì…ë‹ˆë‹¤.')
######################
st.divider()

#### ğŸ“Œ 3. ì´ë¯¸ì§€ ë‹¤ë£¨ê¸° ####
## í´ë¦­ì„ í•´ì•¼ì§€ë§Œ ì´ë¯¸ì§€ê°€ ë‚˜íƒ€ë‚¨
if st.checkbox('ì´ë¯¸ì§€ ë³´ê¸°'):
    st.title("3. ì´ë¯¸ì§€ ë‹¤ë£¨ê¸°")
    image_url = "https://media1.tenor.com/m/A64OVBBLwU4AAAAd/%EB%82%98%EB%A3%A8%ED%86%A0%EC%82%AC%EC%8A%A4%EC%BC%80%EC%8B%B8%EC%9B%80%EC%88%98%EC%A4%80-anime.gif"

    # HTMLì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    st.markdown(f'<img src="{image_url}" width="700" height="350">', unsafe_allow_html=True)
    ##########################
    st.divider()

#### ğŸ“Œ 4. í™”ë©´ êµ¬ë¶„ ë‹¤ë£¨ê¸° ####
st.title("4. í™”ë©´ êµ¬ë¶„ ë‹¤ë£¨ê¸°")
# íƒ­ìœ¼ë¡œ í™”ë©´ êµ¬ë¶„
tab1, tab2 = st.tabs(["Tab 1", "Tab2"])
with tab1:
    tab1.write("tab1ì— ëŒ€í•œ ë‚´ìš©")
    st.metric(label="Temp1", value="273 K", delta="1.2 K")
with tab2:
    tab2.write("tab2ì— ëŒ€í•œ ë‚´ìš©")
    st.metric(label="Temp2", value="273 K", delta="-1.2 K")

st.divider()

# columnsë¡œ í™”ë©´ êµ¬ë¶„
col1, col2 = st.columns(2)
with col1:
    st.write("ì²«ë²ˆì§¸ ì—´")
    
with col2:
    st.write("ë‘ë²ˆì§¸ ì—´")
    

##########################
st.divider()

#### ğŸ“Œ 5. ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ####
st.title("5. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°")
st.write("""
#### Iris ë°ì´í„°ì…‹
- 3ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.
- 4ê°œì˜ featureê°€ ìˆìŠµë‹ˆë‹¤.
- 150ê°œì˜ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.         
- ëª¨ë¸: RandomForestClassifier
#### ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ì‹¶ìœ¼ì‹œë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.

""")
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
iris = load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns=iris.feature_names)

## ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, ëª¨ë¸ì„ í•™ìŠµí•˜ê³  pickleë¡œ ì €ì¥
if st.button("ëª¨ë¸ í•™ìŠµ"):
    ## ëª¨ë¸ì´ í•™ìŠµë ë•Œê¹Œì§€ ìŠ¤í•€
    with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘..."):
        time.sleep(3)
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X, y)
        ## â­ï¸â­ï¸â­ï¸â­ï¸ ëª¨ë¸ ë¡œì»¬ì— ì €ì¥ â­ï¸â­ï¸â­ï¸â­ï¸
        ## joblib.dump(model, './iris_model.pkl')
        ## ë§Œì¼ ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì‹¶ë‹¤ë©´
        ## model = joblib.load('./iris_model.pkl')
        
        st.write(f"âœ… ëª¨ë¸ì´ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.")
##########################

# ë¶“ê½ƒ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡
st.header("ğŸŒº ë¶“ê½ƒ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡")

model = joblib.load('./iris_model.pkl')
# ì…ë ¥ ë°›ê¸°
col1, col2, col3, col4 = st.columns(4)
with col1:
    sepal_length = st.slider("Sepal length", float(df['sepal length (cm)'].min()), float(df['sepal length (cm)'].max()))
with col2:
    sepal_width = st.slider("Sepal width", float(df['sepal width (cm)'].min()), float(df['sepal width (cm)'].max()))
with col3:
    petal_length = st.slider("Petal length", float(df['petal length (cm)'].min()), float(df['petal length (cm)'].max()))
with col4:    
    petal_width = st.slider("Petal width", float(df['petal width (cm)'].min()), float(df['petal width (cm)'].max()))

# ì…ë ¥ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
input_data = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]], columns=iris.feature_names)

# ì˜ˆì¸¡
prediction = model.predict(input_data)

species_mapping = {
    0: 'Setosa',
    1: 'Versicolor',
    2: 'Virginica'
}
predicted_species = species_mapping[prediction[0]]
# ì˜ˆì¸¡ í™•ë¥  
prediction_proba = model.predict_proba(input_data)

st.write(f"âœ… ì˜ˆì¸¡ëœ ë¶“ê½ƒ ì¢…ë¥˜ => {iris.target_names[prediction][0]}")
## ì˜ˆì¸¡ ê²°ê³¼ê°€ OOì´ë©´ Alertì°½
if predicted_species == 'Setosa':
    st.warning(f"ğŸ”´ ê²½ê³ : Setosaë¼ëŠ” ì˜ˆì¸¡ì´ ë‚˜ì˜¤ë©´ {prediction_proba[0][0]}í™•ë¥ ë¡œ ê²½ê³ ë¥¼ í•©ë‹ˆë‹¤.")
elif predicted_species == 'Versicolor':
    st.success(f"ğŸŸ¢ ì•ˆì „: Versicolorë¼ëŠ” ì˜ˆì¸¡ì´ ë‚˜ì˜¤ë©´ {prediction_proba[0][1]}í™•ë¥ ë¡œ ì•ˆì „í•©ë‹ˆë‹¤.")
else:
    st.info(f"ğŸŸ¡ ì •ë³´: Virginicaë¼ëŠ” ì˜ˆì¸¡ì´ ë‚˜ì˜¤ë©´ {prediction_proba[0][2]}í™•ë¥ ë¡œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
st.write("ğŸ¤– í™•ë¥  TABLE")
st.write(pd.DataFrame(prediction_proba, columns=iris.target_names))

st.divider()

if st.checkbox('ë‹¤ì´ìºìŠ¤íŒ… ë°ì´í„°ë¡œ í•´ë³¼ê¹Œìš”?'):

    FILE_PATH = 'data/casting.csv'

    ## 2. ëŒ€ì‹œë³´ë“œ ì œëª©
    st.title('Streamlit í•¸ì¦ˆì˜¨')

    ## 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    def load_data(FILE_PATH):
        data = pd.read_csv(FILE_PATH, encoding='cp949', index_col=0)
        ## âœ… ì „ì²˜ë¦¬ ë¡œì§ 
        data['registration_time'] = pd.to_datetime(data['registration_time'])
        ## 3-1. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        df = data[['registration_time','mold_code','count',
            'molten_temp', 'facility_operation_cycleTime',
            'production_cycletime', 'low_section_speed', 'high_section_speed',
            'molten_volume', 'cast_pressure', 'biscuit_thickness',
            'upper_mold_temp1', 'upper_mold_temp2', 'upper_mold_temp3',
            'lower_mold_temp1', 'lower_mold_temp2', 'lower_mold_temp3',
            'sleeve_temperature', 'physical_strength', 'Coolant_temperature',
            'passorfail']]
        ## 3-2. mold_codeë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        df['mold_code'] = df['mold_code'].astype(str)
        ## 3-3. ë‚ ì§œ, ì‹œê°„, ìš”ì¼ ì»¬ëŸ¼ ìƒì„±
        df['date'] = df['registration_time'].dt.date
        df['hour'] = df['registration_time'].dt.hour
        df['weekday'] = df['registration_time'].dt.weekday ## 0:ì›”ìš”ì¼, 6:ì¼ìš”ì¼
        df['date_time'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['hour'].astype(str) + ':00:00')
        df['weekday'] = df['weekday'].map({0:'ì›”', 1:'í™”', 2:'ìˆ˜', 3:'ëª©', 4:'ê¸ˆ', 5:'í† ', 6:'ì¼'})
        # 3-4. í‰ê·  ìƒì‚°ì‹œê°„ ê³„ì‚°
        df['average_cycle_time'] = (df['facility_operation_cycleTime'] + df['production_cycletime']) / 2
        ## 3-5. ì •ìƒí’ˆ, ë¶ˆëŸ‰í’ˆ ìƒì„±
        df['pass'] = df['passorfail'].apply(lambda x: 1 if x == 0 else 0)
        df['fail'] = df['passorfail'].apply(lambda x: 1 if x == 1 else 0)

        ## 3-6. ìš”ì¼ë³„, ì‹œê°„ë³„, mold_codeë³„ í‰ê·  ìƒì‚° ì‹œê°„ê³¼ ìƒì‚°ëŸ‰ ê³„ì‚°
        grouped_data = df.groupby(['date_time','mold_code','weekday','hour'])['average_cycle_time'].agg(['mean','median','count']).reset_index()
        ## 3-7. ìš”ì¼ë³„, ì‹œê°„ë³„, mold_codeë³„ ì–‘í’ˆ/ë¶ˆëŸ‰í’ˆ ìˆ˜ ê³„ì‚°
        grouped_data2 = df.groupby(['date_time','mold_code','weekday','hour'])['pass'].sum().reset_index(name='pass_count')
        grouped_data3 = df.groupby(['date_time','mold_code','weekday','hour'])['fail'].sum().reset_index(name='error_count')
        ## 3-8. ë°ì´í„° ë³‘í•©
        merge_grouped_df = pd.merge(grouped_data, grouped_data2,
                                    on=['date_time','mold_code','weekday','hour'], how='left') 

        merge_grouped_df = pd.merge(merge_grouped_df, grouped_data3,
                                        on=['date_time','mold_code','weekday','hour'], how='left')

        ## 3-9. ìƒì‚°ëŸ‰, ìƒì‚°ì‹œê°„, ì–‘í’ˆ/ë¶ˆëŸ‰í’ˆ ë¹„ìœ¨ ê³„ì‚°
        merge_grouped_df['mean'] = merge_grouped_df['mean'].round(1)
        merge_grouped_df['median'] = merge_grouped_df['median'].round(1)
        merge_grouped_df['error_ratio'] = (merge_grouped_df['error_count'] / merge_grouped_df['count']).round(2)
        merge_grouped_df['pass_ratio'] = 1 - merge_grouped_df['error_ratio'].round(2)
        merge_grouped_df['date'] = merge_grouped_df['date_time'].dt.date

        return merge_grouped_df

    data = load_data(FILE_PATH)


    ## 4. ì²´í¬ë°•ìŠ¤ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ í™•ì¸í• ì§€ ë§ì§€ ê²°ì •
    if st.checkbox('raw ë°ì´í„° í™•ì¸'):
        st.subheader('raw ë°ì´í„°') 
        st.divider()
        st.write(data)

    ## 5. íˆìŠ¤í† ê·¸ë¨ ì‹œê°í™”
    st.subheader('ì‹œê°„ë³„ ìƒì‚°ëŸ‰ íˆìŠ¤í† ê·¸ë¨')

    # 6. Plotlyë¥¼ ì‚¬ìš©í•œ íˆìŠ¤í† ê·¸ë¨
    fig1 = px.histogram(data, 
                    x=data['hour'], 
                    nbins=24, 
                    color='mold_code',
                    title='ì‹œê°„ë³„ ìƒì‚°ëŸ‰ íˆìŠ¤í† ê·¸ë¨'
                    )

    fig1.update_xaxes(title_text='24ì‹œê°„')
    fig1.update_yaxes(title_text='ìƒì‚°ëŸ‰')

    st.plotly_chart(fig1)

    ## 7. íŠ¹ì • mold_codeì˜ ìƒì‚°ëŸ‰ ì‹œê°í™”
    st.subheader('íŠ¹ì • mold_codeì˜ ìƒì‚°ëŸ‰ ì‹œê°í™”')
    # mold_code ì„ íƒ ì˜µì…˜ ì¶”ê°€
    selected_mold_code = st.selectbox('mold_code ì„ íƒ', data['mold_code'].unique())

    # ì„ íƒí•œ mold_codeì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° í•„í„°ë§
    filtered_data = data[data['mold_code'] == selected_mold_code]

    fig2 = px.histogram(filtered_data, 
                    x='hour', 
                    nbins=24, 
                    title=f'ì‹œê°„ë³„ ìƒì‚°ëŸ‰ íˆìŠ¤í† ê·¸ë¨ (mold_code: {selected_mold_code})'
                    )

    fig2.update_xaxes(title_text='24ì‹œê°„')
    fig2.update_yaxes(title_text='ìƒì‚°ëŸ‰')

    st.plotly_chart(fig2)


    # Streamlitì—ì„œ ë‚ ì§œ ë²”ìœ„ ì„ íƒ ìœ„ì ¯ì„ ê°€ë¡œë¡œ ë°°ì¹˜
    col1, col2, col3 = st.columns(3)

    with col1:
        start_date = st.date_input('ì‹œì‘ ë‚ ì§œ', value=data['date_time'].min())

    with col2:
        end_date = st.date_input('ì¢…ë£Œ ë‚ ì§œ', value=data['date_time'].max())

    with col3:
        # mold_code ì„ íƒ ìœ„ì ¯
        unique_mold_codes = data['mold_code'].unique()
        selected_mold_code = st.multiselect('Mold Code ì„ íƒ', unique_mold_codes)


    # ì„ íƒí•œ ë‚ ì§œ ë²”ìœ„ì— ë§ê²Œ ë°ì´í„° í•„í„°ë§
    filtered_data = data[(data['date_time'] >= pd.to_datetime(start_date)) &
                                    (data['date_time'] <= pd.to_datetime(end_date)) &
                                    (data['mold_code'].isin(selected_mold_code))]

    st.write(filtered_data)

    ## ì •ìƒí’ˆ ë¹„ìœ¨
    pass_ratio = filtered_data['pass_count'].sum() / filtered_data['count'].sum()
    ## ë¶ˆëŸ‰í’ˆ ë¹„ìœ¨
    fail_ratio = filtered_data['error_count'].sum() / filtered_data['count'].sum()

    ## ëª¨ë“ˆí´ë”ì—ì„œ ë„ë„›ì°¨íŠ¸ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    make_chart = MakeChart()
    # í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë„ë„› ì°¨íŠ¸ ìƒì„±
    donut_chart_pass = make_chart.make_donut(pass_ratio.round(2) * 100, 'ì •ìƒí’ˆ', 'green')
    donut_chart_fail = make_chart.make_donut(fail_ratio.round(2) * 100, 'ë¶ˆëŸ‰í’ˆ', 'red')

    with col1:
        st.write('ì •ìƒí’ˆ ë¹„ìœ¨')
        st.altair_chart(donut_chart_pass, use_container_width=True)

    with col2:
        st.write('ë¶ˆëŸ‰í’ˆ ë¹„ìœ¨') 
        st.altair_chart(donut_chart_fail, use_container_width=True)

    # Streamlitì„ ì‚¬ìš©í•´ ëŒ€ì‹œë³´ë“œì— ì°¨íŠ¸ í‘œì‹œ
    tab1, tab2, tab3 = st.tabs(['ìƒì‚°ëŸ‰', 'ë¶ˆëŸ‰ë¥ ', 'í‰ê·  ìƒì‚° ì‹œê°„'])


    with tab1:
        # ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ ìƒì‚°ëŸ‰ ì‹œê°í™”
        fig1 = px.bar(filtered_data, x='date_time', y='count',
            color='weekday',
            title='ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ ìƒì‚°ëŸ‰',
            labels={'count': 'ìƒì‚°ëŸ‰', 'hour': 'ì‹œê°„', 'weekday': 'ìš”ì¼'})

        # xì¶• ë²”ìœ„ ì„¤ì •
        fig1.update_xaxes(range=[str(start_date), str(end_date)])
        st.plotly_chart(fig1)

    with tab2:
            # ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ ë¶ˆëŸ‰ë¥  ì‹œê°í™”
            fig2 = px.bar(filtered_data, x='date_time', y='error_ratio',
                    color='weekday', title='ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ ë¶ˆëŸ‰ë¥ ',
                    labels={'error_ratio': 'ë¶ˆëŸ‰ë¥ ', 'hour': 'ì‹œê°„', 'weekday': 'ìš”ì¼'})
            
            ## 0.8 ë¶€ë¶„ì— ë¹¨ê°„ìƒ‰ ì ì„  ì¶”ê°€
            fig2.add_hline(y=0.8, line_dash='dot', line_color='red', annotation_text='ë¶ˆëŸ‰ë¥  80%', annotation_position='top right')


            # xì¶• ë²”ìœ„ ì„¤ì •
            fig2.update_xaxes(range=[str(start_date), str(end_date)])
            st.plotly_chart(fig2)

    with tab3:

            # ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ í‰ê·  ìƒì‚° ì‹œê°„ ì‹œê°í™”
            fig3 = px.bar(filtered_data, x='date_time', y='mean',
                    color='weekday',
                    title='ë‚ ì§œë³„, ìš”ì¼ë³„, ì‹œê°„ë³„ í‰ê·  ìƒì‚° ì‹œê°„',
                    labels={'mean': 'í‰ê·  ìƒì‚° ì‹œê°„', 'hour': 'ì‹œê°„', 'weekday': 'ìš”ì¼'},
                    color_continuous_scale='Plasma'
                    )

            # xì¶• ë²”ìœ„ ì„¤ì •
            fig3.update_xaxes(range=[str(start_date), str(end_date)])
            st.plotly_chart(fig3)

## 6. í˜ì´ì§€ ì´ë™ 
## pages í´ë”ë¥¼ ë§Œë“¤ê³ , ê° í˜ì´ì§€ë³„ë¡œ íŒŒì¼ì„ ë§Œë“¤ì–´ì„œ í˜ì´ì§€ ì´ë™ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
## ì˜ˆë¥¼ ë“¤ì–´, pages í´ë” ì•ˆì— PredictPage.py íŒŒì¼ì„ ë§Œë“¤ê³ , ì•„ë˜ì™€ ê°™ì´ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
st.markdown('''
- [ ] [ì˜ˆì¸¡íŒŒíŠ¸](/PredictPage)
''')